## ---- load packages ----
# install.packages("unmarked")
library(unmarked)
require(stats4)
require(parallel)
# library(CircStats)
# library(circular)
library(ggcorrplot)
library(ggplot2)
library(dplyr)
library(readr)

# vedere questo link
# https://sites.google.com/site/asrworkshop/home/schedule/r-occupancy-1

## -------------------------------------------------------------------------------------
## ---- DETECTION HISTORIES ----
# I am first going to read in just the detection histories (columns 2-4).
# The commands to do this are:
# dati <- read.csv("data/blgr.csv") # da leggere file csv relativo alle capture histories
# # in cui la prima colonna deve riportare l'ID della trappola
# # le colonne successive (dalla 2 alla 27) i valori 0/1 per le catture
# head(dati)
# #detection data rows are sites, columns are detection replicates
# y<-dati[,2:4] # [,2:27] ## object which contains just the detection histories
# head(y)
# n<-nrow(dati)

# detection histories (rows are sites (traps), columns are replicates (trapping occasions))

# leggo i file delle singole sessioni
# s1: dati di luglio
# s2: dati di agosto-settembre
# numero di occasioni deve essere 23, quindi numero di colonne 24
# numero di righe deve essere 75
dati2014.s2 <- read.csv("data/detection_histories/2014/dati.histories.2014.sessione2.csv", sep=";")
dati2015.s1 <- read.csv("data/detection_histories/2015/dati.histories.2015.sessione1.csv", sep=",")
dati2015.s1 <- cbind(dati2015.s1, occ21=NA, occ22=NA, occ23=NA) # aggiunte colonne mancanti per arrivare ad avere 23 occasioni
dati2015.s2 <- read.csv("data/detection_histories/2015/dati.histories.2015.sessione2.csv", sep=";")[1:75,]
dati2016.s1 <- read.csv("data/detection_histories/2016/dati.histories.2016.sessione1.csv", sep=";")[,-19]
dati2016.s1 <- cbind(dati2016.s1, occ18=NA, occ19=NA, occ20=NA, occ21=NA, occ22=NA, occ23=NA)
righe <- dati2016.s1[1:25,]
righe[1:25, 2:24] <- NA
righe[1:25, 1] <- 51:75
dati2016.s1 <- rbind(dati2016.s1,righe)
dati2016.s2 <- read.csv("data/detection_histories/2016/dati.histories.2016.sessione2.csv", sep=";")
dati2016.s2 <- cbind(dati2016.s2, occ19=NA, occ20=NA, occ21=NA, occ22=NA, occ23=NA)
righe <- dati2016.s2[1:15,]
righe[1:15, 2:24] <- NA
righe[1:15, 1] <- 61:75
dati2016.s2 <- rbind(dati2016.s2,righe)
dati2017.s2 <- read.csv("data/detection_histories/2017/dati.histories.2017.sessione2.csv", sep=";")
dati2017.s2 <- cbind(dati2017.s2, occ19=NA, occ20=NA, occ21=NA, occ22=NA, occ23=NA)
righe <- dati2017.s2[1:25,]
righe[1:25, 2:24] <- NA
righe[1:25, 1] <- 51:75
dati2017.s2 <- rbind(dati2017.s2,righe)
dati2018.s1 <- read.csv("data/detection_histories/2018/dati.histories.2018.session1.csv", sep=";")
dati2018.s2 <- read.csv("data/detection_histories/2018/dati.histories.2018.session2.csv", sep=";")


# unisco i file delle singole sessioni
sessioni <- c("session1","session2","session3","session4","session5","session6","session7","session8")
occasions <- "occ"
occasion.no <- 1:23
occs.temp <- expand.grid(occasions, occasion.no, sessioni)
nomi <- paste(occs.temp$Var3, occs.temp$Var1, occs.temp$Var2,sep="")
dati <- cbind(dati2014.s2[,-1],
              dati2015.s1[,-1],
              dati2015.s2[,-1],
              dati2016.s1[,-1],
              dati2016.s2[,-1],
              dati2017.s2[,-1],
              dati2018.s1[,-1],
              dati2018.s2[,-1])
colnames(dati) <- nomi
head(dati)
tail(dati)
n<-nrow(dati)
n # number of sites (traps in this case), serve poi per creare le info giuste per alba/tramonto
y <- dati
## -------------------------------------------------------------------------------------


## -------------------------------------------------------------------------------------
## ---- COVARIATES ----
# Next, let's read in the site-specific covariates in columns 5-9. 
# # nel caso dell'esempio:
# #site level (individual) covariates
# blgr.site<-dati[,5:9]

# leggo il file delle covariate - uguali per tutti gli anni
# numero di righe deve essere 75
# numero di colonne dipende da numero di variabili ambientali
# dati.cov <- read.csv("data/DatiTrap-SiteCovs/siteCovs-Cogne-DEF2018_def.csv", sep=";")
# dati.cov <- read_delim("data/DatiTrap-SiteCovs/siteCovs-Cogne-DEF2018_def.csv", 
                                         # ";", escape_double = FALSE, trim_ws = TRUE)
# leggo i dati aggiornati da Bianca al 24/01/19
dati.cov <- read.csv("data/DatiTrap-SiteCovs/siteCovs-Cogne-DEF2018_Bianca.csv", sep=";")
# dati.cov <- read_delim("data/DatiTrap-SiteCovs/siteCovs-Cogne-DEF2018_Bianca.csv", 
#                        ";", escape_double = FALSE, trim_ws = TRUE)
# dati.cov$ottavi_veg2018 <- as.numeric(dati.cov$ottavi_veg2018)
dati.cov <- dati.cov[,-1] # tolta la prima colonna che era soltanto il numero di riga
dati.cov <- dati.cov[,1:16] # tolte le colonne vuote in fondo
# dati.cov <- dati.cov[,-2] # tolta la colonna della sessione
# dati.cov <- dati.cov[,-15] # tolta la colonna dell'anno
head(dati.cov) # #site level (individual) covariates
#
# per le analisi, abbiamo assunto che non vi fossero cambiamenti significativi nella copertura vegetazionale e nella flora
# nell'intorno di ciascuna trappola, questo per quanto riguarda i dati dal 2014 al 2017
#
# nel 2018, visto che sono stati raccolti nuovi dati utilizzando una misurazione in ottavi
# verifichiamo se esistono differenze significative tra le percentuali rilevate, rispettivamente,
# nel 2014 e nel 2018
t.test(dati.cov$perc_veg, dati.cov$perc_veg2018, paired = TRUE)
summary(dati.cov[,c("perc_veg","perc_veg2018")])
#
# come si vede dai risultati del t.test e del summary, non pare vi siano differenze sign.
# da ora in avanti preferisco usare i dati in ottavi, perché la procedura di rilievo sul
# campo è più standardizzata
# quindi utilizzo i dati del 2018, per le trappole da 1 a 50, e per le rimanenti, che 
# non sono state posizionate nel 2018, converto le vecchie percentuali in ottavi
# dati.cov$ottavi_veg <- cut(dati.cov$perc_veg,seq(0,100,12.5), labels=FALSE)
dati.cov$ottavi_veg <- round(dati.cov$perc_veg/12.5,0)
t.test(dati.cov$ottavi_veg2018, dati.cov$ottavi_veg, paired = TRUE)
summary(dati.cov[,c("ottavi_veg","ottavi_veg2018")])
# dati.cov$ottavi_veg <- factor(dati.cov$ottavi_veg)
#
# a questo punto 'ripulisco' il dataset eliminando colonne che sicuramente non saranno usate
dati.cov %>% 
  mutate(perc_veg = NULL,
         perc_veg2018 = NULL,
         ottavi_veg2018 = NULL) -> dati.cov
#
# salvo il file
# write.csv(dati.cov, file = "data/DatiTrap-SiteCovs/siteCovs-Cogne-DEF2018_def_def.csv")

## -------------------------------------------------------------------------------------


## -------------------------------------------------------------------------------------
## ---- TIME-SPECIFIC COVARIATES ----
# There are no time-specific covariates per se in this analysis, 
# but we are going to want to test for time-specific variation in detection. 
# To do that, we will need to create a time variable that behaves like a factor 
# (rather than a numerical values) in R.  
# We could accomplish this by creating dummy variables in a dataframe, 
# but it is easier to define a factor in R.
# The code to do this is simple:
#create time factor and use as covariate
#observation level (time specific) covariates
# time<-as.factor(rep(c(1,2,3),n))
# blgr.obs<-data.frame(time)
# dim(blgr.obs)
# # We confirm that time is a factor:
# time
# class(blgr.obs)
# dim(blgr.obs)

# # Fake data
# R <- 4 # number of sites
# J <- 3 # number of visits
# 
# obs.covs <- list(
#   x3 = matrix(c(
#     -1,0,1,
#     -2,0,0,
#     -3,1,0,
#     0,0,0), nrow=R, ncol=J, byrow=TRUE),
#   x4 = matrix(c(
#     'a','b','c',
#     'd','b','a',
#     'a','a','c',
#     'a','b','a'), nrow=R, ncol=J, byrow=TRUE))

# alba <- as.matrix(read.csv("data/DatiTrap-ObsCovs/alba.csv", sep = ";", header=FALSE)[1:75,])
# temp <- as.matrix(read.csv("data/DatiTrap-ObsCovs/temp.csv", sep = ";", header=FALSE)[1:75,])
# rain <- as.matrix(read.csv("data/DatiTrap-ObsCovs/rain.csv", sep = ";", header=FALSE)[1:75,])
alba <- as.matrix(read.csv("data/DatiTrap-ObsCovs/alba2018.csv", sep = ";", header=FALSE)[1:75,])
# temp <- as.numeric(as.matrix(read.csv("data/DatiTrap-ObsCovs/temperature2018.csv", sep = ";", header=FALSE, as.is = TRUE, colClasses = "character")[1:75,]))
# rain <- as.numeric(as.matrix(read.csv("data/DatiTrap-ObsCovs/precipitazioni2018.csv", sep = ";", header=FALSE, as.is = TRUE, colClasses = "character")[1:75,]))
temp <- as.matrix(read_delim("data/DatiTrap-ObsCovs/temperature2018.csv", 
                      "\t", escape_double = FALSE, col_names = FALSE,
                      trim_ws = TRUE, col_types = cols(.default = col_double())))
rain <- as.matrix(read_delim("data/DatiTrap-ObsCovs/precipitazioni2018.csv", 
                             "\t", escape_double = FALSE, col_names = FALSE,
                             trim_ws = TRUE, col_types = cols(.default = col_double())))
alba[1,1] <- "Tr" # correggo un errore nella lettura del file
# 2018-12-13 controllato preparazione file e mandato istruzioni a Bianca fino a qui, il resto è ancora da controllare!
# 2019-01-09 rifatto fino a qui usando nuovi file di Bianca, ok! proseguire :-D

R <- 75 # number of sites
# J <- 6*23 # number of visits
J <- 8*23 # number of visits

obs.covs <- list(
  alba = matrix(c(alba), nrow=R, ncol=J, byrow=FALSE),
  temp = matrix(c(temp), nrow=R, ncol=J, byrow=FALSE),
  rain = matrix(c(rain), nrow=R, ncol=J, byrow=FALSE)
  # year = matrix(c(year), nrow=R, ncol=J, byrow=FALSE),
  # season = matrix(c(), nrow=R, ncol=J, byrow=FALSE),
  )

# season <- as.matrix(read.csv("datiR/Cogne/DatiTrap-SeasonCovs/season.csv", sep = ";", header=FALSE)[1:75,])
# year <- as.matrix(read.csv("datiR/Cogne/DatiTrap-SeasonCovs/year.csv", sep = ",", header=FALSE)[1:75,])
# time.seq <- as.matrix(read.csv("datiR/Cogne/DatiTrap-SeasonCovs/time.csv", sep = ",", header=FALSE)[1:75,])
season <- as.matrix(read.csv("data/DatiTrap-SeasonCovs/season.csv", sep = ";", header=FALSE)[1:75,])
year <- as.matrix(read.csv("data/DatiTrap-SeasonCovs/year.csv", sep = ",", header=FALSE)[1:75,])
time.seq <- as.matrix(read.csv("data/DatiTrap-SeasonCovs/time.csv", sep = ",", header=FALSE)[1:75,])
time.interval <- time.seq
#
# indico i mesi passati tra una sessione e l'altra
time.interval[,1] <- 1 # sett 2014
time.interval[,2] <- 11 # luglio 2015
time.interval[,3] <- 1 # agosto-settembre 2015
time.interval[,4] <- 11 # luglio 2016
time.interval[,5] <- 1 # agosto-settembre 2016
time.interval[,6] <- 12 # agosto-settembre 2017
time.interval[,7] <- 11 # luglio 2018
time.interval[,8] <- 1 # agosto-settembre 2018
M <- 75
N <- 8
session.covs <- list(
  year = matrix(c(year), nrow=M, ncol=N, byrow=FALSE),
  season = matrix(c(season), nrow=M, ncol=N, byrow=FALSE),
  #time.seq = matrix(c(time.seq), nrow=M, ncol=N, byrow=FALSE)
  time.interval = matrix(c(time.interval), nrow=M, ncol=N, byrow=FALSE)
)



## -------------------------------------------------------------------------------------
## ---- UNMARKED DATA FRAME ----
# ?unmarkedFrameOccu
# Finally, we put the detection histories and covariates together into a single unmarked data frame called blgr:
#put everything together in unmarked data frame
#note that covariate can come from separate files
# blgr <- unmarkedFrameOccu(y = y, siteCovs = blgr.site, obsCovs = blgr.obs)
# # SINGLE SEASON - MARCO
# blgr <- unmarkedFrameOccu(y = y, # capture histories (specifiche per la sessione 1 o la sessione 2)
#                           siteCovs = dati.cov, # dati.cov, uguali per le due sessioni
#                           obsCovs = obs.covs) # alba/tramonto, specifico per la sessione 1 o la sessione 2
# # which can be summarized by
# #summary of unmarked data frame
# summary(blgr)

# # MULTI SEASON - ELENA
# umf <- unmarkedMultFrame(y = y, # capture histories (specifiche per la sessione 1 o la sessione 2)
#                           numPrimary = 6,
#                           siteCovs = dati.cov, # dati.cov, uguali per le due sessioni
#                           obsCovs = obs.covs,
#                           yearlySiteCovs = session.covs) # alba/tramonto, specifico per la sessione 1 o la sessione 2
# umf
# # which can be summarized by
# #summary of unmarked data frame
# summary(umf)

## ---- MULTI SEASON - BIANCA ----
umf <- unmarkedMultFrame(y = y, # capture histories (specifiche per la sessione 1 o la sessione 2)
                         numPrimary = 8,
                         siteCovs = dati.cov, # dati.cov, uguali per le due sessioni
                         obsCovs = obs.covs,
                         yearlySiteCovs = session.covs) # alba/tramonto, specifico per la sessione 1 o la sessione 2
umf
# which can be summarized by
#summary of unmarked data frame
summary(umf)


## -------------------------------------------------------------------------------------

# prima di procedere con le analisi vere e proprie, sistemo alcune cose nei dati delle covariate
# es. calcolo mediana e intervallo interquartile del diametro delle rocce
sc <- siteCovs(umf)
MDR <- apply(sc[,5:7], 1, median)
IQR <- apply(sc[,5:7], 1, IQR)#, na.rm=TRUE)
# trasformo i dati dell'esposizione
# trasformazione e successiva analisi dei dati di esposizione
# expc <- circular(sc$aspect_deg, type="angles", units="degrees", template='none', zero=0, rotation="clock")
# plot(expc)
Esp.tr <- vector("numeric", length(sc$aspect_deg))
for (i in 1:length(sc$aspect_deg)) {
  if (sc$aspect_deg[i] > 180) Esp.tr[i] <- sc$aspect_deg[i]-360 else Esp.tr[i] <- sc$aspect_deg[i]
}
hist(Esp.tr)
# outlier.identify(Esp.tr)
# raggruppo i dati delle specie vegetali dominanti, facendo soltanto 3 gruppi: graminacee, muschio, tutte le altre
dominante <- vector("character", length(sc$dominant_s))
dominante[sc$dominant_s != "Graminacee" & sc$dominant_s != "Muschio"] <- "Other_sp"
dominante[sc$dominant_s == "Graminacee"] <- "Graminacee"
dominante[sc$dominant_s == "Muschio"] <- "Muschio"
dominante[42] <- "Other_sp"

sc2 <- cbind(sc, MDR, IQR, Esp.tr, dominante)
# sc.def <- sc2[,c(10,11,12,15,16,17,18)]
# sc.def <- sc2[,c("slope_degr","perc_veg","n_species","MDR","IQR","Esp.tr","dominante")]
sc.def <- sc2[,c("slope_degr","n_species","ottavi_veg","MDR","IQR","Esp.tr","dominante")]
siteCovs(umf) <- sc.def
#
# controllo
summary(umf)


#---------------------------------------------------------
## ---- analisi di correlazione delle variabili esplicative ----
# togliendo la colonna della specie dominante e convertendo temporaneamente gli ottavi in numero
sc.def.temp <- na.omit(sc.def)
sc.def.temp$ottavi_veg <- as.numeric(sc.def.temp$ottavi_veg)
corr <- round(cor(sc.def.temp[,-7], method = "pearson"), 2)
corr
# vedere se ci sono valori superiori a 0.5
# correlazione tra ottavi_veg e n_species

# codice sotto non funziona, ma era solo per grafico
# non è vero, funziona di nuovo!! :-D
ggcorrplot(corr)
ggcorrplot(corr, type = "lower", sig.level = 0.69, p.mat = abs(corr))
# p.mat <- cor_pmat(sc.def[,-7], method = "pearson")
# ggcorrplot(corr)
# ggcorrplot::ggcorrplot(corr, type = "lower", sig.level = 0.7, p.mat = p.mat)


save(umf, file="output/umf_cogne.RData", compress=FALSE)
